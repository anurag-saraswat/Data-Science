{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Death Event or heart failure using feautres such as platelets , ejection fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Set\n",
      "<bound method NDFrame.head of       age  creatinine_phosphokinase  ejection_fraction  platelets  \\\n",
      "174  65.0                       198                 35  281000.00   \n",
      "44   60.0                       588                 60  194000.00   \n",
      "292  52.0                       190                 38  382000.00   \n",
      "136  65.0                        59                 60  172000.00   \n",
      "54   60.0                       260                 38  255000.00   \n",
      "..    ...                       ...                ...        ...   \n",
      "157  50.0                       250                 25  262000.00   \n",
      "279  55.0                        84                 38  451000.00   \n",
      "114  60.0                       754                 40  328000.00   \n",
      "132  46.0                       719                 40  263358.03   \n",
      "215  73.0                       582                 35  203000.00   \n",
      "\n",
      "     serum_creatinine  serum_sodium  time  DEATH_EVENT  \n",
      "174              0.90           137   146            0  \n",
      "44               1.10           142    33            1  \n",
      "292              1.00           140   258            0  \n",
      "136              0.90           137   107            0  \n",
      "54               2.20           132    45            1  \n",
      "..                ...           ...   ...          ...  \n",
      "157              1.00           136   120            0  \n",
      "279              1.30           136   246            0  \n",
      "114              1.20           126    91            0  \n",
      "132              1.18           137   107            0  \n",
      "215              1.30           134   195            0  \n",
      "\n",
      "[299 rows x 8 columns]>\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./DataSet/heart_failure_clinical_records_dataset.csv')\n",
    "data = data.sample(frac=1)\n",
    "data = data.drop(columns=[\"diabetes\", \"high_blood_pressure\",\"sex\", \"smoking\" ,\"anaemia\"])\n",
    "print(\"Data Set\")\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70-30 Split\n",
    "\n",
    "Data_Train_70 = data.iloc[:int(len(data)*0.7)]\n",
    "Data_Test_30 = data.iloc[int(len(data)*0.7):]\n",
    "\n",
    "y_train_70 = np.array(Data_Train_70[\"DEATH_EVENT\"])\n",
    "x_train_70 = np.array(Data_Train_70.drop(columns=[\"DEATH_EVENT\"]))\n",
    "y_test_30 = np.array(Data_Test_30[\"DEATH_EVENT\"])\n",
    "x_test_30 = np.array(Data_Test_30.drop(columns=[\"DEATH_EVENT\"]))\n",
    "\n",
    "# Normalizing Data\n",
    "\n",
    "u = np.mean(x_train_70,axis=0)\n",
    "std = np.std(x_train_70,axis=0)\n",
    "\n",
    "x_train_70 = (x_train_70-u)/std\n",
    "x_test_30 = (x_test_30-u)/std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80-20 Split\n",
    "Data_Train_80 = data.iloc[:int(len(data)*0.8)]\n",
    "Data_Test_20 = data.iloc[int(len(data)*0.8):]\n",
    "\n",
    "y_train_80 = np.array(Data_Train_80[\"DEATH_EVENT\"])\n",
    "x_train_80 = np.array(Data_Train_80.drop(columns=[\"DEATH_EVENT\"]))\n",
    "y_test_20 = np.array(Data_Test_20[\"DEATH_EVENT\"])\n",
    "x_test_20 = np.array(Data_Test_20.drop(columns=[\"DEATH_EVENT\"]))\n",
    "\n",
    "# Normalizing Data\n",
    "\n",
    "u = np.mean(x_train_80,axis=0)\n",
    "std = np.std(x_train_80,axis=0)\n",
    "\n",
    "x_train_80 = (x_train_80-u)/std\n",
    "x_test_20 = (x_test_20-u)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90-10 Split\n",
    "Data_Train_90 = data.iloc[:int(len(data)*0.8)]\n",
    "Data_Test_10 = data.iloc[int(len(data)*0.8):]\n",
    "\n",
    "y_train_90 = np.array(Data_Train_90[\"DEATH_EVENT\"])\n",
    "x_train_90 = np.array(Data_Train_90.drop(columns=[\"DEATH_EVENT\"]))\n",
    "y_test_10 = np.array(Data_Test_10[\"DEATH_EVENT\"])\n",
    "x_test_10 = np.array(Data_Test_10.drop(columns=[\"DEATH_EVENT\"]))\n",
    "\n",
    "# Normalizing Data\n",
    "\n",
    "u = np.mean(x_train_90,axis=0)\n",
    "std = np.std(x_train_90,axis=0)\n",
    "\n",
    "x_train_90 = (x_train_90-u)/std\n",
    "x_test_10 = (x_test_10-u)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Half Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "percept = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 70-30  split\n",
    "percept.fit(x_train_70,y_train_70)\n",
    "score_70 = percept.score(x_test_30,y_test_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 80-20  split\n",
    "percept.fit(x_train_80,y_train_80)\n",
    "score_80 = percept.score(x_test_20,y_test_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 90-10  split\n",
    "percept.fit(x_train_90,y_train_90)\n",
    "score_90 = percept.score(x_test_10,y_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Score/Accuracy using Half Space Classifier (Using Perceptron): \n",
      "Percentage Score at 70-30 split : 73.33333333333333\n",
      "Percentage Score at 80-20 split : 78.33333333333333\n",
      "Percentage Score at 90-10 split : 78.33333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Prediction Score/Accuracy using Half Space Classifier (Using Perceptron): \")\n",
    "print(\"Percentage Score at 70-30 split :\",score_70*100)\n",
    "print(\"Percentage Score at 80-20 split :\",score_80*100)\n",
    "print(\"Percentage Score at 90-10 split :\",score_90*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 70-30  split\n",
    "model.fit(x_train_70,y_train_70)\n",
    "score_70 = model.score(x_test_30,y_test_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 80-20 split\n",
    "\n",
    "model.fit(x_train_80,y_train_80)\n",
    "score_80 = model.score(x_test_20,y_test_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 90-10 split\n",
    "model.fit(x_train_90,y_train_90)\n",
    "score_90 = model.score(x_test_10,y_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Score/Accuracy using In-Built Logistic Regression Function: \n",
      "Percentage Score at 70-30 split : 88.88888888888889\n",
      "Percentage Score at 80-20 split : 90.0\n",
      "Percentage Score at 90-10 split : 90.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Prediction Score/Accuracy using In-Built Logistic Regression Function: \")\n",
    "print(\"Percentage Score at 70-30 split :\",score_70*100)\n",
    "print(\"Percentage Score at 80-20 split :\",score_80*100)\n",
    "print(\"Percentage Score at 90-10 split :\",score_90*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SGD Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def hypothesis(X,w):\n",
    "    '''\n",
    "        x - entire array(m,n+1)\n",
    "        w - np.array(n+1,1)\n",
    "    '''\n",
    "    return sigmoid(np.dot(X,w))\n",
    "\n",
    "def error(X,y,w):\n",
    "    '''\n",
    "       x - (m,n+1)\n",
    "       y - (m,1)\n",
    "       w = (n+1,1)\n",
    "       return:\n",
    "            scaler_value = loss\n",
    "    '''\n",
    "\n",
    "    hypo = hypothesis(X,w)\n",
    "    err = -1*np.mean((y*np.log(hypo) + ((1-y) *np.log(1-hypo))))\n",
    "    \n",
    "    return err\n",
    "\n",
    "def gradient(X,y,w):\n",
    "    '''\n",
    "       x - (m,n+1)\n",
    "       y - (m,1)\n",
    "       w = (n+1,1)\n",
    "       return:\n",
    "            gradient vector - (n+1,1)\n",
    "    '''\n",
    "    \n",
    "    hypo = hypothesis(X,w)\n",
    "    grad = -np.dot(X.T,(y-hypo))\n",
    "    #print(y.shape,hypo.shape)\n",
    "    m = X.shape[0]\n",
    "    return grad/m\n",
    "    \n",
    "\n",
    "def gradient_descent(X,y,lr=0.5,max_itr = 500):\n",
    "    \n",
    "    n = X.shape[1]\n",
    "    \n",
    "    w = np.zeros((n,1))\n",
    "    \n",
    "    error_list = []\n",
    "\n",
    "    for i in range(max_itr) :\n",
    "        err = error(X,y,w)\n",
    "        error_list.append(err)\n",
    "        grad = gradient(X,y,w)\n",
    "        \n",
    "        # Update w\n",
    "        w = w - lr*grad\n",
    "        \n",
    "    return w,error_list\n",
    "        \n",
    "#Converting confidence score into corresponding label    \n",
    "def predict(x,w):\n",
    "    h = hypothesis(x,w)\n",
    "    output = np.zeros(h.shape)\n",
    "    output[h>0.5] = 1\n",
    "    output = output.astype('int')\n",
    "    return output\n",
    "\n",
    "#Finding Accurecy of model\n",
    "def accuracy(actual,pred):\n",
    "    acc = np.sum(actual == pred)/actual.shape[0]\n",
    "    return acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# For 70-30  split\n",
    "\n",
    "x_train = x_train_70\n",
    "y_train = y_train_70\n",
    "\n",
    "x_test = x_test_30\n",
    "y_test = y_test_30\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "ones = np.ones((x_train.shape[0],1))\n",
    "x_train = np.hstack((ones,x_train))\n",
    "\n",
    "ones = np.ones((x_test.shape[0],1))\n",
    "x_test = np.hstack((ones,x_test))\n",
    "\n",
    "w,error_list = gradient_descent(x_train,y_train)\n",
    "y_predict = predict(x_test,w)\n",
    "score_70 = accuracy(y_test,y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 80-20  split\n",
    "\n",
    "x_train = x_train_80\n",
    "y_train = y_train_80\n",
    "\n",
    "x_test = x_test_20\n",
    "y_test = y_test_20\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "ones = np.ones((x_train.shape[0],1))\n",
    "x_train = np.hstack((ones,x_train))\n",
    "\n",
    "ones = np.ones((x_test.shape[0],1))\n",
    "x_test = np.hstack((ones,x_test))\n",
    "\n",
    "w,error_list = gradient_descent(x_train,y_train)\n",
    "y_predict = predict(x_test,w)\n",
    "score_80 = accuracy(y_test,y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 90-10  split\n",
    "\n",
    "x_train = x_train_90\n",
    "y_train = y_train_90\n",
    "\n",
    "x_test = x_test_10\n",
    "y_test = y_test_10\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "ones = np.ones((x_train.shape[0],1))\n",
    "x_train = np.hstack((ones,x_train))\n",
    "\n",
    "ones = np.ones((x_test.shape[0],1))\n",
    "x_test = np.hstack((ones,x_test))\n",
    "\n",
    "w,error_list = gradient_descent(x_train,y_train)\n",
    "y_predict = predict(x_test,w)\n",
    "score_90 = accuracy(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Score/Accuracy using Logistic Regression using Gradient Descent: \n",
      "Percentage Score at 70-30 split : 86.66666666666667\n",
      "Percentage Score at 80-20 split : 90.0\n",
      "Percentage Score at 90-10 split : 90.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Prediction Score/Accuracy using Logistic Regression using Gradient Descent: \")\n",
    "print(\"Percentage Score at 70-30 split :\",score_70)\n",
    "print(\"Percentage Score at 80-20 split :\",score_80)\n",
    "print(\"Percentage Score at 90-10 split :\",score_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 70-30  split\n",
    "svm.fit(x_train_70,y_train_70)\n",
    "score_70 = svm.score(x_test_30,y_test_30)\n",
    "num = svm.support_vectors_\n",
    "vect_70 = num.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 80-20 split\n",
    "svm.fit(x_train_80,y_train_80)\n",
    "score_80 = svm.score(x_test_20,y_test_20)\n",
    "num = svm.support_vectors_\n",
    "vect_80 = num.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 90-10 split\n",
    "svm.fit(x_train_90,y_train_90)\n",
    "score_90 = svm.score(x_test_10,y_test_10)\n",
    "num = svm.support_vectors_\n",
    "vect_90 = num.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Score using SVM Gaussian Kernel: \n",
      "Percentage Score at 70-30 split : 85.55555555555556\n",
      "Percentage Score at 80-20 split : 90.0\n",
      "Percentage Score at 90-10 split : 90.0\n",
      "\n",
      " Number of support vector using SVM Gaussian Kernel: \n",
      "Number of support vectors in 70-30 split : 122\n",
      "Number of support vectors in 80-20 split : 133\n",
      "Number of support vectors in 90-10 split : 133\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Prediction Score using SVM Gaussian Kernel: \")\n",
    "print(\"Percentage Score at 70-30 split :\",score_70*100)\n",
    "print(\"Percentage Score at 80-20 split :\",score_80*100)\n",
    "print(\"Percentage Score at 90-10 split :\",score_90*100)\n",
    "\n",
    "print(\"\\n Number of support vector using SVM Gaussian Kernel: \")\n",
    "print(\"Number of support vectors in 70-30 split :\",vect_70)\n",
    "print(\"Number of support vectors in 80-20 split :\",vect_80)\n",
    "print(\"Number of support vectors in 90-10 split :\",vect_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel = 'poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 70-30  split\n",
    "svm.fit(x_train_70,y_train_70)\n",
    "score_70 = svm.score(x_test_30,y_test_30)\n",
    "num = svm.support_vectors_\n",
    "vect_70 = num.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 80-20 split\n",
    "svm.fit(x_train_80,y_train_80)\n",
    "score_80 = svm.score(x_test_20,y_test_20)\n",
    "num = svm.support_vectors_\n",
    "vect_80 = num.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 90-10 split\n",
    "svm.fit(x_train_90,y_train_90)\n",
    "score_90 = svm.score(x_test_10,y_test_10)\n",
    "num = svm.support_vectors_\n",
    "vect_80 = num.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Score using SVM Polynomial Kernel: \n",
      "Percentage Score at 70-30 split : 85.55555555555556\n",
      "Percentage Score at 80-20 split : 91.66666666666666\n",
      "Percentage Score at 90-10 split : 91.66666666666666\n",
      "\n",
      " Number of support vector using SVM Polynomial Kernel: \n",
      "Number of support vectors in 70-30 split : 127\n",
      "Number of support vectors in 80-20 split : 140\n",
      "Number of support vectors in 90-10 split : 133\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Prediction Score using SVM Polynomial Kernel: \")\n",
    "print(\"Percentage Score at 70-30 split :\",score_70*100)\n",
    "print(\"Percentage Score at 80-20 split :\",score_80*100)\n",
    "print(\"Percentage Score at 90-10 split :\",score_90*100)\n",
    "\n",
    "print(\"\\n Number of support vector using SVM Polynomial Kernel: \")\n",
    "print(\"Number of support vectors in 70-30 split :\",vect_70)\n",
    "print(\"Number of support vectors in 80-20 split :\",vect_80)\n",
    "print(\"Number of support vectors in 90-10 split :\",vect_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 70-30  split\n",
    "svm.fit(x_train_70,y_train_70)\n",
    "score_70 = svm.score(x_test_30,y_test_30)\n",
    "num = svm.support_vectors_\n",
    "vect_70 = num.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 80-20 split\n",
    "svm.fit(x_train_80,y_train_80)\n",
    "score_80 = svm.score(x_test_20,y_test_20)\n",
    "num = svm.support_vectors_\n",
    "vect_80 = num.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 90-10 split\n",
    "svm.fit(x_train_90,y_train_90)\n",
    "score_90 = svm.score(x_test_10,y_test_10)\n",
    "num = svm.support_vectors_\n",
    "vect_90 = num.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Score using SVM Linear Kernel: \n",
      "Percentage Score at 70-30 split : 88.88888888888889\n",
      "Percentage Score at 80-20 split : 88.33333333333333\n",
      "Percentage Score at 90-10 split : 88.33333333333333\n",
      "\n",
      " Number of support vector using SVM Linear Kernel: \n",
      "Number of support vectors in 70-30 split : 98\n",
      "Number of support vectors in 80-20 split : 108\n",
      "Number of support vectors in 90-10 split : 108\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Prediction Score using SVM Linear Kernel: \")\n",
    "print(\"Percentage Score at 70-30 split :\",score_70*100)\n",
    "print(\"Percentage Score at 80-20 split :\",score_80*100)\n",
    "print(\"Percentage Score at 90-10 split :\",score_90*100)\n",
    "\n",
    "print(\"\\n Number of support vector using SVM Linear Kernel: \")\n",
    "print(\"Number of support vectors in 70-30 split :\",vect_70)\n",
    "print(\"Number of support vectors in 80-20 split :\",vect_80)\n",
    "print(\"Number of support vectors in 90-10 split :\",vect_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
